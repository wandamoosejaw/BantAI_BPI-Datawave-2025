{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "665eb7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BantAI Travel-Aware Risk-Based Authentication System\n",
    "Separate implementation for intelligent travel vs threat detection\n",
    "\n",
    "Distinguishes between:\n",
    "- Legitimate Filipino travelers (OFWs, tourists, business)\n",
    "- Account compromise/cyber attacks\n",
    "\n",
    "Features:\n",
    "- Travel plausibility analysis\n",
    "- Behavioral consistency scoring\n",
    "- Impossible travel detection\n",
    "- OFW-friendly risk assessment\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from geopy.distance import geodesic\n",
    "import warnings\n",
    "import pickle\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class BantAI_TravelAware:\n",
    "    \"\"\"\n",
    "    Travel-Aware Risk-Based Authentication for Filipino Banking\n",
    "    \n",
    "    Smart enough to distinguish between:\n",
    "    - Juan traveling to Dubai for work (legitimate)\n",
    "    - Hacker accessing from Moscow (threat)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cache_file=None, ml_model_path=None, geocode_delay=1.0):\n",
    "        self.user_profiles = {}  # Store user behavioral baselines\n",
    "        self.cache_file = cache_file\n",
    "        self.ml_model_path = ml_model_path\n",
    "        self.geocode_delay = geocode_delay\n",
    "        self.model = None\n",
    "        \n",
    "        # Try to load cached location data first\n",
    "        self.location_coordinates = self._load_cached_locations()\n",
    "        if not self.location_coordinates:\n",
    "            self.location_coordinates = self._load_location_data()\n",
    "            self._cache_locations()\n",
    "            \n",
    "        self.travel_risk_zones = self._define_travel_zones()\n",
    "        self.max_travel_speed_kmh = 900  # Commercial aircraft speed\n",
    "        \n",
    "    def _load_cached_locations(self):\n",
    "        \"\"\"Try to load location data from cache file\"\"\"\n",
    "        if self.cache_file:\n",
    "            try:\n",
    "                with open(self.cache_file, 'r') as f:\n",
    "                    return json.load(f)\n",
    "            except (FileNotFoundError, json.JSONDecodeError):\n",
    "                return None\n",
    "        return None\n",
    "        \n",
    "    def _cache_locations(self):\n",
    "        \"\"\"Save location data to cache file\"\"\"\n",
    "        if self.cache_file and self.location_coordinates:\n",
    "            with open(self.cache_file, 'w') as f:\n",
    "                json.dump(self.location_coordinates, f)\n",
    "    \n",
    "    def _load_location_data(self):\n",
    "        \"\"\"\n",
    "        Load comprehensive geographic coordinates for travel distance calculations\n",
    "        \"\"\"\n",
    "        return {\n",
    "            # PHILIPPINES - Major Cities\n",
    "            'Manila': (14.5995, 120.9842),\n",
    "            'Quezon City': (14.6760, 121.0437),\n",
    "            'Makati': (14.5547, 121.0244),\n",
    "            'Cebu City': (10.3157, 123.8854),\n",
    "            'Davao City': (7.1907, 125.4553),\n",
    "            \n",
    "            # Major OFW Destinations\n",
    "            'Dubai': (25.2048, 55.2708),\n",
    "            'Abu Dhabi': (24.4539, 54.3773),\n",
    "            'Riyadh': (24.7136, 46.6753),\n",
    "            'Singapore': (1.3521, 103.8198),\n",
    "            'Hong Kong': (22.3193, 114.1694),\n",
    "            \n",
    "            # High Risk Areas\n",
    "            'Moscow': (55.7558, 37.6176),\n",
    "            'Beijing': (39.9042, 116.4074),\n",
    "            'Tehran': (35.6892, 51.3890)\n",
    "        }\n",
    "        \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the ML model from the specified path\"\"\"\n",
    "        if self.ml_model_path:\n",
    "            try:\n",
    "                with open(self.ml_model_path, 'rb') as f:\n",
    "                    self.model = pickle.load(f)\n",
    "                print(\"✅ ML model loaded successfully\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error loading ML model: {str(e)}\")\n",
    "                self.model = None\n",
    "\n",
    "    def _define_travel_zones(self):\n",
    "        \"\"\"\n",
    "        Define risk zones for different types of travel destinations\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'ofw_hubs': {\n",
    "                'locations': ['Dubai', 'Abu Dhabi', 'Riyadh'],\n",
    "                'base_risk': 0.2,\n",
    "                'description': 'Major OFW employment hubs'\n",
    "            },\n",
    "            'business_hubs': {\n",
    "                'locations': ['Singapore', 'Hong Kong'],\n",
    "                'base_risk': 0.3,\n",
    "                'description': 'Major business centers'\n",
    "            },\n",
    "            'high_risk': {\n",
    "                'locations': ['Moscow', 'Beijing', 'Tehran'],\n",
    "                'base_risk': 0.8,\n",
    "                'description': 'Known cybercrime hubs'\n",
    "            },\n",
    "            'philippines': {\n",
    "                'locations': ['Manila', 'Quezon City', 'Makati', 'Cebu City', 'Davao City'],\n",
    "                'base_risk': 0.1,\n",
    "                'description': 'Domestic locations'\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Complete BantAI Travel-Aware System\n",
      "==================================================\n",
      "✅ ML model loaded successfully\n",
      "   Model type: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "   Features: ['time_diff', 'distance', 'device_type', 'is_attack_ip', 'login_successful', 'latency']\n",
      "\n",
      "Establishing user baseline...\n",
      "Baseline established for User juan_dela_cruz_123\n",
      "   Home locations: ['Makati', 'Manila']\n",
      "   Countries visited: ['PH']\n",
      "   Common devices: ['mobile']\n",
      "\n",
      "Analyzing test scenarios...\n",
      "\n",
      "OFW Travel to Dubai\n",
      "------------------------------\n",
      "Risk Score: 0.059 (LOW)\n",
      "Action: ALLOW\n",
      "Recommendation: ALLOW: Legitimate travel with consistent behavior.\n",
      "Analysis factors:\n",
      "  - Travel is plausible (Same location or local area)\n",
      "  - Behavior consistency: 100%\n",
      "  - Location: Major OFW employment hubs in Middle East\n",
      "\n",
      "Impossible Travel Attack\n",
      "------------------------------\n",
      "Risk Score: 0.510 (MEDIUM)\n",
      "Action: ALLOW_WITH_OTP\n",
      "Recommendation: ALLOW with SMS OTP: Possible legitimate travel, verify with additional authentication.\n",
      "Analysis factors:\n",
      "  - Travel is plausible (Same location or local area)\n",
      "  - Behavior consistency: 70%\n",
      "  - Location: Known cybercrime and state-sponsored threat locations\n",
      "  - ⚠ Known attack IP\n",
      "  - ⚠ Failed login attempt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Complete BantAI Travel-Aware Risk-Based Authentication System\n",
    "Integrating your streamlined class with full ML functionality\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from geopy.distance import geodesic\n",
    "import warnings\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class BantAI_TravelAware:\n",
    "    \"\"\"\n",
    "    Travel-Aware Risk-Based Authentication for Filipino Banking\n",
    "    \n",
    "    Smart enough to distinguish between:\n",
    "    - Juan traveling to Dubai for work (legitimate)\n",
    "    - Hacker accessing from Moscow (threat)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cache_file=None, ml_model_path=None, geocode_delay=1.0):\n",
    "        self.user_profiles = {}  # Store user behavioral baselines\n",
    "        self.cache_file = cache_file\n",
    "        self.ml_model_path = ml_model_path\n",
    "        self.geocode_delay = geocode_delay\n",
    "        \n",
    "        # ML model components\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.feature_columns = None\n",
    "        self.model_info = {}\n",
    "        \n",
    "        # Try to load cached location data first\n",
    "        self.location_coordinates = self._load_cached_locations()\n",
    "        if not self.location_coordinates:\n",
    "            self.location_coordinates = self._load_location_data()\n",
    "            self._cache_locations()\n",
    "            \n",
    "        self.travel_risk_zones = self._define_travel_zones()\n",
    "        self.max_travel_speed_kmh = 900  # Commercial aircraft speed\n",
    "        \n",
    "    def _load_cached_locations(self):\n",
    "        \"\"\"Try to load location data from cache file\"\"\"\n",
    "        if self.cache_file:\n",
    "            try:\n",
    "                with open(self.cache_file, 'r') as f:\n",
    "                    return json.load(f)\n",
    "            except (FileNotFoundError, json.JSONDecodeError):\n",
    "                return None\n",
    "        return None\n",
    "        \n",
    "    def _cache_locations(self):\n",
    "        \"\"\"Save location data to cache file\"\"\"\n",
    "        if self.cache_file and self.location_coordinates:\n",
    "            with open(self.cache_file, 'w') as f:\n",
    "                json.dump(self.location_coordinates, f)\n",
    "    \n",
    "    def _load_location_data(self):\n",
    "        \"\"\"Load comprehensive geographic coordinates for travel distance calculations\"\"\"\n",
    "        return {\n",
    "            # PHILIPPINES - Major Cities\n",
    "            'Manila': (14.5995, 120.9842),\n",
    "            'Quezon City': (14.6760, 121.0437),\n",
    "            'Makati': (14.5547, 121.0244),\n",
    "            'Taguig': (14.5176, 121.0509),\n",
    "            'Pasig': (14.5764, 121.0851),\n",
    "            'Cebu City': (10.3157, 123.8854),\n",
    "            'Davao City': (7.1907, 125.4553),\n",
    "            'Iloilo City': (10.7202, 122.5621),\n",
    "            'Bacolod': (10.6740, 122.9540),\n",
    "            \n",
    "            # MIDDLE EAST - Major OFW Destinations\n",
    "            'Dubai': (25.2048, 55.2708),\n",
    "            'Abu Dhabi': (24.4539, 54.3773),\n",
    "            'Sharjah': (25.3573, 55.4033),\n",
    "            'Riyadh': (24.7136, 46.6753),\n",
    "            'Jeddah': (21.4858, 39.1925),\n",
    "            'Doha': (25.2854, 51.5310),\n",
    "            'Kuwait City': (29.3117, 47.4818),\n",
    "            'Manama': (26.2285, 50.5860),\n",
    "            'Muscat': (23.5880, 58.3829),\n",
    "            \n",
    "            # ASIA PACIFIC - Business and Tourism\n",
    "            'Singapore': (1.3521, 103.8198),\n",
    "            'Hong Kong': (22.3193, 114.1694),\n",
    "            'Tokyo': (35.6762, 139.6503),\n",
    "            'Seoul': (37.5665, 126.9780),\n",
    "            'Bangkok': (13.7563, 100.5018),\n",
    "            'Kuala Lumpur': (3.1390, 101.6869),\n",
    "            'Jakarta': (6.2088, 106.8456),\n",
    "            \n",
    "            # HIGH RISK LOCATIONS\n",
    "            'Moscow': (55.7558, 37.6176),\n",
    "            'St. Petersburg': (59.9311, 30.3609),\n",
    "            'Beijing': (39.9042, 116.4074),\n",
    "            'Shanghai': (31.2304, 121.4737),\n",
    "            'Tehran': (35.6892, 51.3890),\n",
    "            'Pyongyang': (39.0392, 125.7625),\n",
    "            \n",
    "            # NORTH AMERICA - Filipino Communities\n",
    "            'Los Angeles': (34.0522, -118.2437),\n",
    "            'San Francisco': (37.7749, -122.4194),\n",
    "            'New York': (40.7128, -74.0060),\n",
    "            'Toronto': (43.6532, -79.3832),\n",
    "            'Vancouver': (49.2827, -123.1207),\n",
    "            \n",
    "            # OCEANIA\n",
    "            'Sydney': (-33.8688, 151.2093),\n",
    "            'Melbourne': (-37.8136, 144.9631),\n",
    "        }\n",
    "        \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the ML model from the specified path\"\"\"\n",
    "        if not self.ml_model_path:\n",
    "            print(\"No ML model path specified\")\n",
    "            return False\n",
    "            \n",
    "        if not os.path.exists(self.ml_model_path):\n",
    "            print(f\"ML model file not found: {self.ml_model_path}\")\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            with open(self.ml_model_path, 'rb') as f:\n",
    "                model_data = pickle.load(f)\n",
    "            \n",
    "            # Extract components from the loaded data\n",
    "            if isinstance(model_data, dict):\n",
    "                self.model = model_data.get('model')\n",
    "                self.scaler = model_data.get('scaler')\n",
    "                self.feature_columns = model_data.get('feature_columns')\n",
    "                self.model_info = model_data.get('model_info', {})\n",
    "                \n",
    "                print(\"✅ ML model loaded successfully\")\n",
    "                print(f\"   Model type: {type(self.model)}\")\n",
    "                print(f\"   Features: {self.feature_columns}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"❌ Invalid model file format\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading ML model: {str(e)}\")\n",
    "            self.model = None\n",
    "            return False\n",
    "\n",
    "\n",
    "    def _define_travel_zones(self):\n",
    "        \"\"\"\n",
    "        Define comprehensive risk zones for different types of travel destinations\n",
    "        Based on Filipino travel patterns, OFW destinations, and threat intelligence\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'ofw_hubs': {\n",
    "                'locations': [\n",
    "                    # Middle East - Major OFW employment destinations\n",
    "                    'Dubai', 'Abu Dhabi', 'Sharjah', 'Ajman', 'Al Ain',\n",
    "                    'Riyadh', 'Jeddah', 'Dammam', 'Mecca', 'Medina',\n",
    "                    'Doha', 'Kuwait City', 'Manama', 'Muscat',\n",
    "                    'Amman', 'Beirut', 'Baghdad', 'Tehran', 'Isfahan', 'Mashhad'\n",
    "                ],\n",
    "                'base_risk': 0.2,\n",
    "                'description': 'Major OFW employment hubs in Middle East'\n",
    "            },\n",
    "            'business_hubs': {\n",
    "                'locations': [\n",
    "                    # Asia Pacific business centers\n",
    "                    'Singapore', 'Hong Kong', 'Macau',\n",
    "                    'Tokyo', 'Osaka', 'Nagoya', 'Kyoto', 'Yokohama',\n",
    "                    'Seoul', 'Busan', 'Incheon',\n",
    "                    'Bangkok', 'Phuket', 'Pattaya', \n",
    "                    'Kuala Lumpur', 'Johor Bahru', 'Penang',\n",
    "                    'Jakarta', 'Bali', 'Surabaya',\n",
    "                    'Ho Chi Minh City', 'Hanoi', 'Da Nang',\n",
    "                    # Global financial centers\n",
    "                    'London', 'Manchester', 'Birmingham', 'Edinburgh', 'Glasgow',\n",
    "                    'Frankfurt', 'Zurich', 'Geneva', 'Amsterdam', 'Brussels'\n",
    "                ],\n",
    "                'base_risk': 0.25,\n",
    "                'description': 'Regional and global business centers'\n",
    "            },\n",
    "            'diaspora_hubs': {\n",
    "                'locations': [\n",
    "                    # United States - Large Filipino communities\n",
    "                    'Los Angeles', 'San Francisco', 'San Diego', 'San Jose',\n",
    "                    'Las Vegas', 'Phoenix', 'Seattle', 'Portland', 'Sacramento', 'Fresno',\n",
    "                    'New York', 'Jersey City', 'Philadelphia', 'Washington DC', 'Boston',\n",
    "                    'Chicago', 'Detroit', 'Miami', 'Orlando', 'Tampa',\n",
    "                    'Houston', 'Dallas', 'Austin', 'San Antonio', 'Denver', 'Atlanta',\n",
    "                    'Honolulu', 'Anchorage',\n",
    "                    # Canada - Filipino diaspora\n",
    "                    'Toronto', 'Vancouver', 'Montreal', 'Calgary', 'Edmonton',\n",
    "                    'Ottawa', 'Winnipeg', 'Quebec City', 'Hamilton',\n",
    "                    # Australia/New Zealand - Filipino communities\n",
    "                    'Sydney', 'Melbourne', 'Brisbane', 'Perth', 'Adelaide',\n",
    "                    'Canberra', 'Gold Coast', 'Newcastle',\n",
    "                    'Auckland', 'Wellington', 'Christchurch'\n",
    "                ],\n",
    "                'base_risk': 0.3,\n",
    "                'description': 'Major Filipino diaspora communities'\n",
    "            },\n",
    "            'tourism_destinations': {\n",
    "                'locations': [\n",
    "                    # Europe - Common tourist destinations\n",
    "                    'Paris', 'Lyon', 'Marseille', 'Rome', 'Milan', 'Naples', 'Venice',\n",
    "                    'Madrid', 'Barcelona', 'Berlin', 'Munich', 'Vienna',\n",
    "                    'Stockholm', 'Oslo', 'Copenhagen', 'Helsinki',\n",
    "                    'Prague', 'Budapest', 'Warsaw', 'Athens', 'Istanbul', 'Ankara',\n",
    "                    'Dublin',\n",
    "                    # Other popular destinations\n",
    "                    'Phnom Penh', 'Vientiane', 'Yangon', 'Colombo',\n",
    "                    'Mumbai', 'Delhi', 'Bangalore', 'Chennai', 'Hyderabad', 'Kolkata', 'Pune', 'Ahmedabad'\n",
    "                ],\n",
    "                'base_risk': 0.35,\n",
    "                'description': 'Popular tourist and cultural destinations'\n",
    "            },\n",
    "            'developing_markets': {\n",
    "                'locations': [\n",
    "                    # South/Southeast Asia\n",
    "                    'Dhaka', 'Kathmandu', 'Karachi', 'Lahore', 'Islamabad', 'Kabul',\n",
    "                    # Central Asia\n",
    "                    'Tashkent', 'Almaty', 'Bishkek', 'Dushanbe',\n",
    "                    # Africa\n",
    "                    'Cairo', 'Alexandria', 'Cape Town', 'Johannesburg', 'Durban',\n",
    "                    'Nairobi', 'Addis Ababa', 'Casablanca', 'Tunis', 'Algiers',\n",
    "                    # South America\n",
    "                    'São Paulo', 'Rio de Janeiro', 'Brasília', 'Salvador',\n",
    "                    'Buenos Aires', 'Córdoba', 'Lima', 'Santiago', 'Quito', 'Montevideo'\n",
    "                ],\n",
    "                'base_risk': 0.45,\n",
    "                'description': 'Developing markets with moderate risk'\n",
    "            },\n",
    "            'high_risk_regions': {\n",
    "                'locations': [\n",
    "                    # Africa - Higher risk areas\n",
    "                    'Lagos', 'Abuja', 'Kano', 'Ibadan',\n",
    "                    # South America - Crime hotspots\n",
    "                    'Bogotá', 'Medellín', 'Caracas', 'La Paz'\n",
    "                ],\n",
    "                'base_risk': 0.65,\n",
    "                'description': 'Higher risk regions with security concerns'\n",
    "            },\n",
    "            'cybercrime_hubs': {\n",
    "                'locations': [\n",
    "                    # Russia - Major cybercrime source\n",
    "                    'Moscow', 'St. Petersburg', 'Novosibirsk', 'Yekaterinburg',\n",
    "                    # China - State-sponsored threats\n",
    "                    'Beijing', 'Shanghai', 'Shenzhen', 'Guangzhou', \n",
    "                    'Hangzhou', 'Chengdu',\n",
    "                    # North Korea - State actors\n",
    "                    'Pyongyang', 'Hamhung', 'Chongjin',\n",
    "                    # Eastern Europe - Cybercrime centers\n",
    "                    'Bucharest', 'Minsk', 'Kiev', 'Kharkiv',\n",
    "                    'Chisinau', 'Tirana', 'Skopje', 'Sarajevo'\n",
    "                ],\n",
    "                'base_risk': 0.8,\n",
    "                'description': 'Known cybercrime and state-sponsored threat locations'\n",
    "            },\n",
    "            'philippines_domestic': {\n",
    "                'locations': [\n",
    "                    # Metro Manila\n",
    "                    'Manila', 'Quezon City', 'Makati', 'Taguig', 'Pasig',\n",
    "                    'Mandaluyong', 'Marikina', 'Pasay', 'Parañaque',\n",
    "                    'Las Piñas', 'Muntinlupa', 'Caloocan', 'Valenzuela',\n",
    "                    'Malabon', 'Navotas',\n",
    "                    # Luzon\n",
    "                    'Baguio', 'Angeles', 'San Fernando', 'Dagupan',\n",
    "                    'Cabanatuan', 'Olongapo', 'Batangas', 'Lipa',\n",
    "                    'Lucena', 'Naga', 'Legazpi', 'Iloilo City',\n",
    "                    'Vigan', 'Tuguegarao', 'Laoag',\n",
    "                    # Visayas\n",
    "                    'Cebu City', 'Mandaue', 'Lapu-Lapu', \n",
    "                    'Bacolod', 'Dumaguete', 'Tacloban', 'Ormoc',\n",
    "                    'Tagbilaran', 'Roxas', 'Kalibo',\n",
    "                    # Mindanao\n",
    "                    'Davao City', 'Cagayan de Oro', 'Zamboanga', 'Butuan',\n",
    "                    'Iligan', 'Cotabato', 'General Santos', 'Koronadal',\n",
    "                    'Kidapawan', 'Dipolog', 'Pagadian', 'Marawi'\n",
    "                ],\n",
    "                'base_risk': 0.05,\n",
    "                'description': 'Philippine domestic locations'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def analyze_user_baseline(self, user_login_history):\n",
    "        \"\"\"Analyze user's normal behavior patterns from login history\"\"\"\n",
    "        user_id = user_login_history[0]['user_id']\n",
    "        \n",
    "        # Extract behavioral patterns\n",
    "        locations = [login['location'] for login in user_login_history]\n",
    "        times = [datetime.strptime(login['timestamp'], '%Y-%m-%d %H:%M:%S') for login in user_login_history]\n",
    "        devices = [login['device_type'] for login in user_login_history]\n",
    "        countries = [login['country'] for login in user_login_history]\n",
    "        \n",
    "        # Calculate baseline patterns\n",
    "        baseline = {\n",
    "            'user_id': user_id,\n",
    "            'home_locations': list(set(loc for loc, country in zip(locations, countries) if country == 'PH')),\n",
    "            'common_devices': list(set(devices)),\n",
    "            'typical_hours': [t.hour for t in times],\n",
    "            'login_frequency': len(user_login_history),\n",
    "            'countries_visited': list(set(countries)),\n",
    "            'last_known_location': locations[-1],\n",
    "            'last_login_time': times[-1],\n",
    "            'travel_history': self._extract_travel_history(user_login_history)\n",
    "        }\n",
    "        \n",
    "        # Store user profile\n",
    "        self.user_profiles[user_id] = baseline\n",
    "        \n",
    "        print(f\"Baseline established for User {user_id}\")\n",
    "        print(f\"   Home locations: {baseline['home_locations']}\")\n",
    "        print(f\"   Countries visited: {baseline['countries_visited']}\")\n",
    "        print(f\"   Common devices: {baseline['common_devices']}\")\n",
    "        \n",
    "        return baseline\n",
    "    \n",
    "    def _extract_travel_history(self, login_history):\n",
    "        \"\"\"Extract travel patterns from login history\"\"\"\n",
    "        travels = []\n",
    "        \n",
    "        for i in range(1, len(login_history)):\n",
    "            prev_login = login_history[i-1]\n",
    "            curr_login = login_history[i]\n",
    "            \n",
    "            if prev_login['country'] != curr_login['country']:\n",
    "                travel = {\n",
    "                    'from_location': prev_login['location'],\n",
    "                    'to_location': curr_login['location'],\n",
    "                    'from_country': prev_login['country'],\n",
    "                    'to_country': curr_login['country'],\n",
    "                    'time_gap': (datetime.strptime(curr_login['timestamp'], '%Y-%m-%d %H:%M:%S') - \n",
    "                               datetime.strptime(prev_login['timestamp'], '%Y-%m-%d %H:%M:%S')).total_seconds() / 3600,\n",
    "                    'distance_km': self._calculate_distance(prev_login['location'], curr_login['location'])\n",
    "                }\n",
    "                travels.append(travel)\n",
    "        \n",
    "        return travels\n",
    "    \n",
    "    def _calculate_distance(self, location1, location2):\n",
    "        \"\"\"Calculate distance between two locations\"\"\"\n",
    "        if location1 in self.location_coordinates and location2 in self.location_coordinates:\n",
    "            coord1 = self.location_coordinates[location1]\n",
    "            coord2 = self.location_coordinates[location2]\n",
    "            return geodesic(coord1, coord2).kilometers\n",
    "        return 0\n",
    "    \n",
    "    def _get_location_zone(self, location):\n",
    "        \"\"\"Determine which risk zone a location belongs to\"\"\"\n",
    "        for zone_name, zone_data in self.travel_risk_zones.items():\n",
    "            if location in zone_data['locations']:\n",
    "                return zone_name, zone_data['base_risk']\n",
    "        return 'unknown', 0.5\n",
    "    \n",
    "    def analyze_travel_plausibility(self, user_id, new_login):\n",
    "        \"\"\"Analyze if travel to new location is physically plausible\"\"\"\n",
    "        if user_id not in self.user_profiles:\n",
    "            return {\n",
    "                'plausible': False,\n",
    "                'reason': 'No user baseline established',\n",
    "                'risk_modifier': 0.5\n",
    "            }\n",
    "        \n",
    "        profile = self.user_profiles[user_id]\n",
    "        last_location = profile['last_known_location']\n",
    "        last_time = profile['last_login_time']\n",
    "        \n",
    "        new_location = new_login['location']\n",
    "        new_time = datetime.strptime(new_login['timestamp'], '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Calculate travel requirements\n",
    "        distance_km = self._calculate_distance(last_location, new_location)\n",
    "        time_gap_hours = (new_time - last_time).total_seconds() / 3600\n",
    "        \n",
    "        if distance_km == 0:  # Same location or unknown coordinates\n",
    "            return {\n",
    "                'plausible': True,\n",
    "                'reason': 'Same location or local area',\n",
    "                'risk_modifier': 0.0,\n",
    "                'distance_km': distance_km,\n",
    "                'time_gap_hours': time_gap_hours\n",
    "            }\n",
    "        \n",
    "        # Calculate minimum travel time\n",
    "        min_travel_time_hours = distance_km / self.max_travel_speed_kmh\n",
    "        buffer_time_hours = 4  # Airport procedures, layovers, etc.\n",
    "        required_time_hours = min_travel_time_hours + buffer_time_hours\n",
    "        \n",
    "        # Check plausibility\n",
    "        if time_gap_hours >= required_time_hours:\n",
    "            return {\n",
    "                'plausible': True,\n",
    "                'reason': f'Sufficient time for travel ({time_gap_hours:.1f}h vs {required_time_hours:.1f}h required)',\n",
    "                'risk_modifier': 0.0,\n",
    "                'distance_km': distance_km,\n",
    "                'time_gap_hours': time_gap_hours,\n",
    "                'required_time_hours': required_time_hours\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'plausible': False,\n",
    "                'reason': f'Impossible travel: {distance_km:.0f}km in {time_gap_hours:.1f}h (need {required_time_hours:.1f}h)',\n",
    "                'risk_modifier': 0.8,\n",
    "                'distance_km': distance_km,\n",
    "                'time_gap_hours': time_gap_hours,\n",
    "                'required_time_hours': required_time_hours\n",
    "            }\n",
    "    \n",
    "    def analyze_behavioral_consistency(self, user_id, new_login):\n",
    "        \"\"\"Check if user behavior remains consistent despite location change\"\"\"\n",
    "        if user_id not in self.user_profiles:\n",
    "            return {'consistency_score': 0.5, 'factors': ['No baseline']}\n",
    "        \n",
    "        profile = self.user_profiles[user_id]\n",
    "        consistency_factors = []\n",
    "        consistency_score = 1.0\n",
    "        \n",
    "        # Device consistency\n",
    "        if new_login['device_type'] in profile['common_devices']:\n",
    "            consistency_factors.append('Known device type')\n",
    "        else:\n",
    "            consistency_score -= 0.3\n",
    "            consistency_factors.append('New device type')\n",
    "        \n",
    "        # Time pattern consistency\n",
    "        new_hour = datetime.strptime(new_login['timestamp'], '%Y-%m-%d %H:%M:%S').hour\n",
    "        if new_hour in profile['typical_hours'] or abs(new_hour - np.mean(profile['typical_hours'])) <= 3:\n",
    "            consistency_factors.append('Consistent login time')\n",
    "        else:\n",
    "            consistency_score -= 0.2\n",
    "            consistency_factors.append('Unusual login time')\n",
    "        \n",
    "        # Previous travel history\n",
    "        if new_login['country'] in profile['countries_visited']:\n",
    "            consistency_factors.append('Previously visited country')\n",
    "            consistency_score += 0.1\n",
    "        else:\n",
    "            consistency_factors.append('First visit to country')\n",
    "        \n",
    "        return {\n",
    "            'consistency_score': max(0, min(1, consistency_score)),\n",
    "            'factors': consistency_factors\n",
    "        }\n",
    "    \n",
    "    def ml_risk_prediction(self, last_login, new_login):\n",
    "        \"\"\"Calculate ML-based risk score for login pair\"\"\"\n",
    "        if self.model is None or self.scaler is None:\n",
    "            return 0.5  # Default risk if no model\n",
    "        \n",
    "        try:\n",
    "            # Create feature vector\n",
    "            features = self._create_feature_vector(last_login, new_login)\n",
    "            \n",
    "            # Scale features\n",
    "            features_scaled = self.scaler.transform([features])\n",
    "            \n",
    "            # Get prediction\n",
    "            risk_prob = self.model.predict_proba(features_scaled)[0][1]\n",
    "            return risk_prob\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ML prediction error: {e}\")\n",
    "            return 0.5\n",
    "    \n",
    "    def _create_feature_vector(self, last_login, new_login):\n",
    "        \"\"\"Create feature vector for ML model\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Time difference\n",
    "        if isinstance(last_login.get('timestamp'), str):\n",
    "            last_time = datetime.strptime(last_login['timestamp'], '%Y-%m-%d %H:%M:%S')\n",
    "        else:\n",
    "            last_time = last_login.get('timestamp', datetime.now())\n",
    "        \n",
    "        new_time = datetime.strptime(new_login['timestamp'], '%Y-%m-%d %H:%M:%S')\n",
    "        time_diff = (new_time - last_time).total_seconds() / 3600\n",
    "        features.append(time_diff)\n",
    "        \n",
    "        # Distance\n",
    "        distance = self._calculate_distance(\n",
    "            last_login.get('location', 'Manila'),\n",
    "            new_login.get('location', 'Manila')\n",
    "        )\n",
    "        features.append(distance)\n",
    "        \n",
    "        # Device type (encoded)\n",
    "        device_encoding = {'mobile': 0, 'desktop': 1, 'tablet': 2}\n",
    "        features.append(device_encoding.get(new_login.get('device_type', 'mobile'), 0))\n",
    "        \n",
    "        # Technical indicators\n",
    "        features.append(1 if new_login.get('is_attack_ip', False) else 0)\n",
    "        features.append(1 if new_login.get('login_successful', True) else 0)\n",
    "        features.append(new_login.get('latency', 100))\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def calculate_travel_aware_risk(self, user_id, new_login):\n",
    "        \"\"\"Calculate comprehensive travel-aware risk score\"\"\"\n",
    "        risk_components = {}\n",
    "        \n",
    "        # 1. Location zone risk\n",
    "        zone, base_location_risk = self._get_location_zone(new_login['location'])\n",
    "        risk_components['location_zone'] = base_location_risk\n",
    "        \n",
    "        # 2. Travel plausibility\n",
    "        travel_analysis = self.analyze_travel_plausibility(user_id, new_login)\n",
    "        risk_components['travel_plausibility'] = travel_analysis['risk_modifier']\n",
    "        \n",
    "        # 3. Behavioral consistency\n",
    "        behavior_analysis = self.analyze_behavioral_consistency(user_id, new_login)\n",
    "        behavior_risk = 1 - behavior_analysis['consistency_score']\n",
    "        risk_components['behavioral_inconsistency'] = behavior_risk\n",
    "        \n",
    "        # 4. Technical indicators\n",
    "        technical_risk = 0.0\n",
    "        technical_factors = []\n",
    "        \n",
    "        if new_login.get('is_attack_ip', False):\n",
    "            technical_risk += 0.4\n",
    "            technical_factors.append('Known attack IP')\n",
    "        \n",
    "        if new_login.get('high_latency', False):\n",
    "            technical_risk += 0.2\n",
    "            technical_factors.append('High network latency')\n",
    "        \n",
    "        if not new_login.get('login_successful', True):\n",
    "            technical_risk += 0.3\n",
    "            technical_factors.append('Failed login attempt')\n",
    "        \n",
    "        risk_components['technical_indicators'] = technical_risk\n",
    "        \n",
    "        # 5. ML Model prediction\n",
    "        ml_risk = 0.5\n",
    "        if self.model is not None and user_id in self.user_profiles:\n",
    "            try:\n",
    "                last_login_data = {\n",
    "                    'timestamp': self.user_profiles[user_id]['last_login_time'].strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'location': self.user_profiles[user_id]['last_known_location'],\n",
    "                }\n",
    "                ml_risk = self.ml_risk_prediction(last_login_data, new_login)\n",
    "            except Exception as e:\n",
    "                print(f\"ML prediction failed: {e}\")\n",
    "        \n",
    "        risk_components['ml_prediction'] = ml_risk\n",
    "        \n",
    "        # Calculate weighted final risk score\n",
    "        weights = {\n",
    "            'location_zone': 0.2,\n",
    "            'travel_plausibility': 0.25,\n",
    "            'behavioral_inconsistency': 0.15,\n",
    "            'technical_indicators': 0.15,\n",
    "            'ml_prediction': 0.25\n",
    "        }\n",
    "        \n",
    "        final_risk = sum(risk_components[component] * weights[component] \n",
    "                        for component in risk_components)\n",
    "        final_risk = min(1.0, final_risk)\n",
    "        \n",
    "        return {\n",
    "            'final_risk_score': final_risk,\n",
    "            'risk_components': risk_components,\n",
    "            'travel_analysis': travel_analysis,\n",
    "            'behavior_analysis': behavior_analysis,\n",
    "            'location_zone': zone,\n",
    "            'technical_factors': technical_factors\n",
    "        }\n",
    "    \n",
    "    def generate_travel_aware_explanation(self, risk_analysis):\n",
    "        \"\"\"Generate human-readable explanation for the risk decision\"\"\"\n",
    "        risk_score = risk_analysis['final_risk_score']\n",
    "        travel_info = risk_analysis['travel_analysis']\n",
    "        behavior_info = risk_analysis['behavior_analysis']\n",
    "        \n",
    "        # Determine risk level\n",
    "        if risk_score < 0.3:\n",
    "            risk_level = \"LOW\"\n",
    "            action = \"ALLOW\"\n",
    "        elif risk_score < 0.6:\n",
    "            risk_level = \"MEDIUM\"\n",
    "            action = \"ALLOW_WITH_OTP\"\n",
    "        else:\n",
    "            risk_level = \"HIGH\"\n",
    "            action = \"BLOCK\" if not travel_info['plausible'] else \"STRICT_VERIFICATION\"\n",
    "        \n",
    "        # Build explanation factors\n",
    "        explanation_factors = []\n",
    "        \n",
    "        # Travel plausibility\n",
    "        if travel_info['plausible']:\n",
    "            explanation_factors.append(f\"Travel is plausible ({travel_info['reason']})\")\n",
    "        else:\n",
    "            explanation_factors.append(f\"⚠ {travel_info['reason']}\")\n",
    "        \n",
    "        # Behavioral consistency\n",
    "        consistency_pct = behavior_info['consistency_score'] * 100\n",
    "        explanation_factors.append(f\"Behavior consistency: {consistency_pct:.0f}%\")\n",
    "        \n",
    "        # Location zone\n",
    "        zone = risk_analysis['location_zone']\n",
    "        zone_info = self.travel_risk_zones.get(zone, {})\n",
    "        explanation_factors.append(f\"Location: {zone_info.get('description', 'Unknown zone')}\")\n",
    "        \n",
    "        # Technical factors\n",
    "        if risk_analysis['technical_factors']:\n",
    "            explanation_factors.extend([f\"⚠ {factor}\" for factor in risk_analysis['technical_factors']])\n",
    "        \n",
    "        return {\n",
    "            'risk_score': risk_score,\n",
    "            'risk_level': risk_level,\n",
    "            'action': action,\n",
    "            'explanation_factors': explanation_factors,\n",
    "            'travel_plausible': travel_info['plausible'],\n",
    "            'behavior_consistent': behavior_info['consistency_score'] > 0.7,\n",
    "            'recommendation': self._get_recommendation(risk_score, travel_info, behavior_info)\n",
    "        }\n",
    "    \n",
    "    def _get_recommendation(self, risk_score, travel_info, behavior_info):\n",
    "        \"\"\"Generate specific recommendations based on analysis\"\"\"\n",
    "        if not travel_info['plausible']:\n",
    "            return \"BLOCK: Impossible travel detected. Manual review required.\"\n",
    "        \n",
    "        if risk_score < 0.3 and behavior_info['consistency_score'] > 0.8:\n",
    "            return \"ALLOW: Legitimate travel with consistent behavior.\"\n",
    "        \n",
    "        if risk_score < 0.6 and travel_info['plausible']:\n",
    "            return \"ALLOW with SMS OTP: Possible legitimate travel, verify with additional authentication.\"\n",
    "        \n",
    "        return \"STRICT VERIFICATION: High-risk login requiring manual review and multiple authentication factors.\"\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    system = test_complete_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8e0a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the complete system\n",
    "def test_complete_system():\n",
    "    \"\"\"Test the complete BantAI system with ML integration\"\"\"\n",
    "    print(\"Testing Complete BantAI Travel-Aware System\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Initialize system\n",
    "    bantai_system = BantAI_TravelAware(\n",
    "        cache_file=\"geocache.json\",\n",
    "        ml_model_path=\"bantai_model.pkl\",\n",
    "        geocode_delay=1.0\n",
    "    )\n",
    "    \n",
    "    # Load ML model\n",
    "    model_loaded = bantai_system.load_model()\n",
    "    \n",
    "    # Sample user baseline\n",
    "    user_id = \"juan_dela_cruz_123\"\n",
    "    juan_history = [\n",
    "        {\n",
    "            'user_id': user_id,\n",
    "            'timestamp': '2024-01-01 09:00:00',\n",
    "            'location': 'Manila',\n",
    "            'country': 'PH',\n",
    "            'device_type': 'mobile',\n",
    "            'login_successful': True\n",
    "        },\n",
    "        {\n",
    "            'user_id': user_id,\n",
    "            'timestamp': '2024-01-03 14:30:00',\n",
    "            'location': 'Makati',\n",
    "            'country': 'PH',\n",
    "            'device_type': 'mobile',\n",
    "            'login_successful': True\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Establish baseline\n",
    "    print(\"\\nEstablishing user baseline...\")\n",
    "    baseline = bantai_system.analyze_user_baseline(juan_history)\n",
    "    \n",
    "    # Test scenarios\n",
    "    test_scenarios = [\n",
    "        {\n",
    "            'name': 'OFW Travel to Dubai',\n",
    "            'login': {\n",
    "                'user_id': user_id,\n",
    "                'timestamp': '2024-01-15 10:00:00',\n",
    "                'location': 'Dubai',\n",
    "                'country': 'AE',\n",
    "                'device_type': 'mobile',\n",
    "                'login_successful': True,\n",
    "                'is_attack_ip': False,\n",
    "                'latency': 120\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'Impossible Travel Attack',\n",
    "            'login': {\n",
    "                'user_id': user_id,\n",
    "                'timestamp': '2024-01-15 11:00:00',\n",
    "                'location': 'Moscow',\n",
    "                'country': 'RU',\n",
    "                'device_type': 'desktop',\n",
    "                'login_successful': False,\n",
    "                'is_attack_ip': True,\n",
    "                'latency': 300\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Analyze scenarios\n",
    "    print(\"\\nAnalyzing test scenarios...\")\n",
    "    for scenario in test_scenarios:\n",
    "        print(f\"\\n{scenario['name']}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Calculate risk\n",
    "        risk_analysis = bantai_system.calculate_travel_aware_risk(\n",
    "            user_id, scenario['login']\n",
    "        )\n",
    "        \n",
    "        # Generate explanation\n",
    "        explanation = bantai_system.generate_travel_aware_explanation(risk_analysis)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"Risk Score: {explanation['risk_score']:.3f} ({explanation['risk_level']})\")\n",
    "        print(f\"Action: {explanation['action']}\")\n",
    "        print(f\"Recommendation: {explanation['recommendation']}\")\n",
    "        \n",
    "        print(\"Analysis factors:\")\n",
    "        for factor in explanation['explanation_factors']:\n",
    "            print(f\"  - {factor}\")\n",
    "    \n",
    "    return bantai_system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0622d26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ML model loaded successfully\n",
      "   Model type: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "   Features: ['time_diff', 'distance', 'device_type', 'is_attack_ip', 'login_successful', 'latency']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bantai_system = BantAI_TravelAware(\n",
    "    cache_file=\"geocache.json\",\n",
    "    ml_model_path=\"bantai_model.pkl\",\n",
    "    geocode_delay=1.0\n",
    ")\n",
    "\n",
    "bantai_system.load_model() # true if the model can run and exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01cf179b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Complete BantAI Travel-Aware System\n",
      "==================================================\n",
      "✅ ML model loaded successfully\n",
      "   Model type: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "   Features: ['time_diff', 'distance', 'device_type', 'is_attack_ip', 'login_successful', 'latency']\n",
      "\n",
      "Establishing user baseline...\n",
      "Baseline established for User juan_dela_cruz_123\n",
      "   Home locations: ['Makati', 'Manila']\n",
      "   Countries visited: ['PH']\n",
      "   Common devices: ['mobile']\n",
      "\n",
      "Analyzing test scenarios...\n",
      "\n",
      "OFW Travel to Dubai\n",
      "------------------------------\n",
      "Risk Score: 0.059 (LOW)\n",
      "Action: ALLOW\n",
      "Recommendation: ALLOW: Legitimate travel with consistent behavior.\n",
      "Analysis factors:\n",
      "  - Travel is plausible (Same location or local area)\n",
      "  - Behavior consistency: 100%\n",
      "  - Location: Major OFW employment hubs in Middle East\n",
      "\n",
      "Impossible Travel Attack\n",
      "------------------------------\n",
      "Risk Score: 0.510 (MEDIUM)\n",
      "Action: ALLOW_WITH_OTP\n",
      "Recommendation: ALLOW with SMS OTP: Possible legitimate travel, verify with additional authentication.\n",
      "Analysis factors:\n",
      "  - Travel is plausible (Same location or local area)\n",
      "  - Behavior consistency: 70%\n",
      "  - Location: Known cybercrime and state-sponsored threat locations\n",
      "  - ⚠ Known attack IP\n",
      "  - ⚠ Failed login attempt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.BantAI_TravelAware at 0x1cc5a85e020>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_complete_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6cafdd",
   "metadata": {},
   "source": [
    "# behavior analysis, when the user log in dagdag feature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BantAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
